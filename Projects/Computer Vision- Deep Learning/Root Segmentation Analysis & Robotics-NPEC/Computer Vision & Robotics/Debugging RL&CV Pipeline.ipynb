{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.morphology import skeletonize, remove_small_objects\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.models import load_model\n",
    "from ot2_gym_wrapper import OT2Env  # Assuming this is where the OT2Env is defined\n",
    "from scipy.spatial.distance import euclidean\n",
    "from skimage.graph import route_through_array\n",
    "import pandas as pd\n",
    "import re\n",
    "from stable_baselines3 import PPO\n",
    "\n",
    "# ------------------------------------\n",
    "# OLD PIPELINE FUNCTIONS\n",
    "# ------------------------------------\n",
    "\n",
    "def f1_score(y_true, y_pred):\n",
    "    def recall_m(y_true, y_pred):\n",
    "        TP = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        Positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = TP / (Positives + K.epsilon())\n",
    "        return recall\n",
    "    \n",
    "    def precision_m(y_true, y_pred):\n",
    "        TP = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        Pred_Positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = TP / (Pred_Positives + K.epsilon())\n",
    "        return precision\n",
    "    \n",
    "    precision_val, recall_val = precision_m(y_true, y_pred), recall_m(y_true, y_pred)\n",
    "    \n",
    "    return 2 * ((precision_val * recall_val) / (precision_val + recall_val + K.epsilon()))\n",
    "\n",
    "\n",
    "def padder(image, divisor, padding_value=(0, 0, 0)):\n",
    "    \"\"\"\n",
    "    Applies balanced padding to an image to make its dimensions divisible by a given divisor.\n",
    "    \"\"\"\n",
    "    original_height, original_width = image.shape[:2]\n",
    "    pad_height = (divisor - (original_height % divisor)) % divisor\n",
    "    pad_width = (divisor - (original_width % divisor)) % divisor\n",
    "\n",
    "    top_pad = pad_height // 2\n",
    "    bottom_pad = pad_height - top_pad\n",
    "    left_pad = pad_width // 2\n",
    "    right_pad = pad_width - left_pad\n",
    "\n",
    "    padded_image = cv2.copyMakeBorder(\n",
    "        image,\n",
    "        top_pad, bottom_pad,\n",
    "        left_pad, right_pad,\n",
    "        cv2.BORDER_CONSTANT,\n",
    "        value=padding_value\n",
    "    )\n",
    "\n",
    "    return padded_image\n",
    "\n",
    "\n",
    "def reduce_noise(image):\n",
    "    \"\"\"\n",
    "    Reduce noise in the input grayscale image using Gaussian blur and morphological operations.\n",
    "    \"\"\"\n",
    "    blurred_image = cv2.GaussianBlur(image, (3, 3), 0)\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))\n",
    "    opened_image = cv2.morphologyEx(blurred_image, cv2.MORPH_OPEN, kernel)\n",
    "    closed_image = cv2.morphologyEx(opened_image, cv2.MORPH_CLOSE, kernel)\n",
    "    return closed_image\n",
    "\n",
    "\n",
    "def morphological_petri_dish_crop(image):\n",
    "    \"\"\"\n",
    "    Detect and crop the Petri dish using adaptive thresholding and morphological operations.\n",
    "    Dynamically adjusts the crop size based on the detected dish dimensions.\n",
    "    \"\"\"\n",
    "    thresh = cv2.adaptiveThreshold(\n",
    "        image, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 11, 2\n",
    "    )\n",
    "    \n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
    "    closed = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)\n",
    "    \n",
    "    contours, _ = cv2.findContours(closed, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    largest_contour = max(contours, key=cv2.contourArea)\n",
    "    \n",
    "    x, y, w, h = cv2.boundingRect(largest_contour)\n",
    "    \n",
    "    size = int(max(w, h) * 0.98)\n",
    "    cx, cy = x + w // 2, y + h // 2\n",
    "    \n",
    "    x1 = max(0, cx - size // 2)\n",
    "    y1 = max(0, cy - size // 2)\n",
    "    x2 = min(image.shape[1], cx + size // 2)\n",
    "    y2 = min(image.shape[0], cy + size // 2)\n",
    "    \n",
    "    cropped_img = image[y1:y2, x1:x2].astype(np.float32) / 255.0\n",
    "    cropped_img = cv2.resize(cropped_img, (size, size), interpolation=cv2.INTER_AREA)\n",
    "    \n",
    "    bbox = (x1, y1, x2, y2)\n",
    "    return cropped_img, bbox\n",
    "\n",
    "\n",
    "def padder_with_overlap(image, divisor, padding_value=(0, 0, 0)):\n",
    "    \"\"\"\n",
    "    Applies overlapping padding to an image to reduce its dimensions such that\n",
    "    the dimensions become divisible by the given divisor.\n",
    "    \"\"\"\n",
    "    original_height, original_width = image.shape[:2]\n",
    "    new_height = original_height - (original_height % divisor)\n",
    "    new_width = original_width - (original_width % divisor)\n",
    "\n",
    "    top_overlap = (original_height - new_height) // 2\n",
    "    bottom_overlap = original_height - new_height - top_overlap\n",
    "    left_overlap = (original_width - new_width) // 2\n",
    "    right_overlap = original_width - new_width - left_overlap\n",
    "\n",
    "    cropped_image = image[top_overlap:original_height-bottom_overlap, left_overlap:original_width-right_overlap]\n",
    "\n",
    "    padded_image = cv2.copyMakeBorder(\n",
    "        cropped_image,\n",
    "        top_overlap, bottom_overlap,\n",
    "        left_overlap, right_overlap,\n",
    "        cv2.BORDER_CONSTANT,\n",
    "        value=padding_value\n",
    "    )\n",
    "\n",
    "    return padded_image, (new_height, new_width)\n",
    "\n",
    "\n",
    "def patch_image(image, patch_size=256, stride=128):\n",
    "    \"\"\"Divides an image into overlapping patches.\"\"\"\n",
    "    patches = []\n",
    "    positions = []\n",
    "    for i in range(0, image.shape[0] - patch_size + 1, stride):\n",
    "        for j in range(0, image.shape[1] - patch_size + 1, stride):\n",
    "            patch = image[i:i + patch_size, j:j + patch_size]\n",
    "            patches.append(patch)\n",
    "            positions.append((i, j))\n",
    "    return np.array(patches), positions\n",
    "\n",
    "\n",
    "def predict_patches(patches, model, batch_size=32):\n",
    "    \"\"\"\n",
    "    Predict a batch of patches using the model for faster inference.\n",
    "    \"\"\"\n",
    "    patches = np.array(patches)\n",
    "    if patches.ndim == 2:  # Ensure the patches have a channel dimension\n",
    "        patches = patches[..., np.newaxis]\n",
    "    predictions = model.predict(patches, batch_size=batch_size)\n",
    "    return predictions\n",
    "\n",
    "\n",
    "def unpatch_image(patches, positions, image_shape, patch_size=256):\n",
    "    \"\"\"Reconstructs the full image from patches.\"\"\"\n",
    "    reconstructed = np.zeros((*image_shape, 1), dtype=np.float32)\n",
    "    patch_count = np.zeros((*image_shape, 1), dtype=np.float32)\n",
    "\n",
    "    for patch, (i, j) in zip(patches, positions):\n",
    "        if patch.ndim == 2:\n",
    "            patch = patch[..., np.newaxis]\n",
    "        \n",
    "        reconstructed[i:i + patch_size, j:j + patch_size, :] += patch\n",
    "        patch_count[i:i + patch_size, j:j + patch_size, :] += 1\n",
    "\n",
    "    reconstructed /= np.maximum(patch_count, 1)\n",
    "    return np.squeeze(reconstructed)\n",
    "\n",
    "\n",
    "def reverse_padding_and_cropping(reconstructed, original_shape, bbox):\n",
    "    \"\"\"\n",
    "    Reverse the effects of cropping and padding on the mask and restore to original dimensions.\n",
    "    \"\"\"\n",
    "    # Initialize final_mask as a 2D array (grayscale)\n",
    "    final_mask = np.zeros(original_shape, dtype=reconstructed.dtype)\n",
    "\n",
    "    x1, y1, x2, y2 = bbox\n",
    "    final_mask[y1:y2, x1:x2] = reconstructed[:y2 - y1, :x2 - x1]\n",
    "\n",
    "    return final_mask\n",
    "\n",
    "\n",
    "# --------------------------------\n",
    "# POST-PROCESSING FUNCTIONS\n",
    "# --------------------------------\n",
    "\n",
    "def process_root_mask(mask, kernel_size=1, iterations=1400, min_area=150):\n",
    "    \"\"\"\n",
    "    Processes the mask to highlight roots, connect disconnected parts, and remove noise.\n",
    "    \"\"\"\n",
    "    mask_normalized = cv2.normalize(mask, None, 0, 255, cv2.NORM_MINMAX)\n",
    "    mask_8bit = np.uint8(mask_normalized)\n",
    "\n",
    "    # Apply Otsu's thresholding to create a binary mask\n",
    "    _, binary_mask = cv2.threshold(mask_8bit, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "    # Morphological kernel\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (kernel_size,kernel_size))\n",
    "\n",
    "    # Opening -> Dilation -> Closing\n",
    "    opened_mask = cv2.morphologyEx(binary_mask, cv2.MORPH_OPEN, kernel)\n",
    "    dilated_mask = cv2.dilate(opened_mask, kernel, iterations=iterations)\n",
    "    closed_mask = cv2.morphologyEx(dilated_mask, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "    # Connected component filtering\n",
    "    num_labels, labels, stats, _ = cv2.connectedComponentsWithStats(closed_mask)\n",
    "    filtered_mask = np.zeros_like(closed_mask)\n",
    "    for i in range(1, num_labels):  # skip background\n",
    "        if stats[i, cv2.CC_STAT_AREA] >= min_area:\n",
    "            filtered_mask[labels == i] = 255\n",
    "\n",
    "    return filtered_mask\n",
    "\n",
    "\n",
    "def skeletonize_mask_skimage(processed_mask, min_size):\n",
    "    \"\"\"\n",
    "    Skeletonizes the given binary mask and removes small objects.\n",
    "    \"\"\"\n",
    "    binary_mask = np.array(processed_mask > 0, dtype=bool)\n",
    "    cleaned_mask = remove_small_objects(binary_mask, min_size=min_size)\n",
    "    skeleton = skeletonize(cleaned_mask)\n",
    "    skeleton_uint8 = np.uint8(skeleton) * 255\n",
    "    return skeleton_uint8\n",
    "\n",
    "\n",
    "def create_overlay(image, mask, alpha=0.5):\n",
    "    \"\"\"\n",
    "    Creates an overlay of the predicted mask on the original image.\n",
    "    \"\"\"\n",
    "    image = cv2.normalize(image, None, 0, 1, cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
    "    mask = cv2.normalize(mask, None, 0, 1, cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
    "    \n",
    "    image_rgb = np.stack([image]*3, axis=-1)  # Convert grayscale to RGB\n",
    "    mask_rgb = np.zeros_like(image_rgb)\n",
    "    mask_rgb[..., 0] = mask\n",
    "    \n",
    "    overlay_image = cv2.addWeighted(image_rgb, 1 - alpha, mask_rgb, alpha, 0)\n",
    "    return overlay_image\n",
    "\n",
    "\n",
    "def find_endpoints(skeleton):\n",
    "    \"\"\"\n",
    "    Detect endpoints in a skeletonized image.\n",
    "    Endpoints are pixels with only one neighbor.\n",
    "    \"\"\"\n",
    "    skeleton_coords = np.column_stack(np.where(skeleton > 0))\n",
    "    endpoints = []\n",
    "    for coord in skeleton_coords:\n",
    "        x, y = coord\n",
    "        neighborhood = skeleton[max(0, x - 1):x + 2, max(0, y - 1):y + 2]\n",
    "        if np.sum(neighborhood) == 2:\n",
    "            endpoints.append((x, y))\n",
    "    return endpoints\n",
    "\n",
    "\n",
    "def measure_root_from_component(component_image, label_id):\n",
    "    \"\"\"\n",
    "    Measure the root length and locate its endpoints for a single segmented component.\n",
    "    Ensures the 'start_point' is the topmost endpoint, and the 'tip' is the farthest from it\n",
    "    (i.e. the bottom one for vertical roots).\n",
    "    \"\"\"\n",
    "    root_mask = (component_image == label_id).astype(np.uint8)\n",
    "    skeleton = skeletonize(root_mask > 0)\n",
    "\n",
    "    endpoints = find_endpoints(skeleton)\n",
    "    if len(endpoints) < 2:\n",
    "        raise ValueError(f\"Not enough endpoints detected for label {label_id}.\")\n",
    "\n",
    "    # Pick topmost endpoint as 'start_point'\n",
    "    start_point = min(endpoints, key=lambda p: p[0])  # row=0 => \"topmost\"\n",
    "    # Pick the farthest endpoint from 'start_point' as 'tip'\n",
    "    tip = max(endpoints, key=lambda p: euclidean(start_point, p))\n",
    "\n",
    "    # Measure root length (Euclidean distance from 'start_point' to all skeleton coords)\n",
    "    skeleton_coords = np.column_stack(np.where(skeleton > 0))\n",
    "    distances = [euclidean(start_point, coord) for coord in skeleton_coords]\n",
    "    length = max(distances)\n",
    "\n",
    "    return length, start_point, tip, skeleton\n",
    "\n",
    "\n",
    "\n",
    "def is_moderately_vertical(skeleton_coords, max_horizontal_to_vertical_ratio=0.5):\n",
    "    \"\"\"\n",
    "    Allow roots that are mostly vertical but exclude highly diagonal roots.\n",
    "    \"\"\"\n",
    "    if len(skeleton_coords) < 2:\n",
    "        return False\n",
    "\n",
    "    y_coords = skeleton_coords[:, 0]\n",
    "    x_coords = skeleton_coords[:, 1]\n",
    "\n",
    "    total_vertical_change = np.ptp(y_coords)\n",
    "    total_horizontal_change = np.ptp(x_coords)\n",
    "\n",
    "    ratio = total_horizontal_change / (total_vertical_change + 1e-6)\n",
    "    return ratio <= max_horizontal_to_vertical_ratio\n",
    "\n",
    "\n",
    "def isolate_and_measure_roots_by_plant(\n",
    "    image_path, \n",
    "    min_area=80, \n",
    "    max_horizontal_to_vertical_ratio=0.5, \n",
    "    min_length=10, \n",
    "    dish_bbox=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Isolate and measure the primary roots of 5 plants aligned horizontally within a Petri dish.\n",
    "    Assigns roots into 5 vertical bins and assigns empty bins a measurement of 0.\n",
    "    \"\"\"\n",
    "\n",
    "    if dish_bbox is None or len(dish_bbox) != 4:\n",
    "        raise ValueError(\"A valid dish_bbox (dish_x1, dish_y1, dish_x2, dish_y2) must be provided.\")\n",
    "\n",
    "    gray = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    if gray is None:\n",
    "        raise FileNotFoundError(f\"Could not read the image: {image_path}\")\n",
    "\n",
    "    retval, labels, stats, centroids = cv2.connectedComponentsWithStats(gray)\n",
    "\n",
    "    results_by_plant = []\n",
    "    for plant_label in range(1, retval):  # Ignore background\n",
    "        plant_area = stats[plant_label, cv2.CC_STAT_AREA]\n",
    "        if plant_area >= min_area:\n",
    "            x, y, w, h = (\n",
    "                stats[plant_label, cv2.CC_STAT_LEFT],\n",
    "                stats[plant_label, cv2.CC_STAT_TOP],\n",
    "                stats[plant_label, cv2.CC_STAT_WIDTH],\n",
    "                stats[plant_label, cv2.CC_STAT_HEIGHT]\n",
    "            )\n",
    "\n",
    "            plant_mask = (labels == plant_label).astype(np.uint8)\n",
    "            plant_image = plant_mask[y:y+h, x:x+w]\n",
    "\n",
    "            retval_roots, root_labels, root_stats, _ = cv2.connectedComponentsWithStats(plant_image)\n",
    "\n",
    "            plant_roots = []\n",
    "            for root_label in range(1, retval_roots):  # Ignore background\n",
    "                root_area = root_stats[root_label, cv2.CC_STAT_AREA]\n",
    "                if root_area >= min_area:\n",
    "                    try:\n",
    "                        length, start, tip, skeleton = measure_root_from_component(root_labels, root_label)\n",
    "                        skeleton_coords = np.column_stack(np.where(skeleton > 0))\n",
    "                        if length >= min_length and is_moderately_vertical(skeleton_coords, max_horizontal_to_vertical_ratio):\n",
    "                            # bounding box in global coords\n",
    "                            root_x_rel = root_stats[root_label, cv2.CC_STAT_LEFT]\n",
    "                            root_y_rel = root_stats[root_label, cv2.CC_STAT_TOP]\n",
    "                            root_w = root_stats[root_label, cv2.CC_STAT_WIDTH]\n",
    "                            root_h = root_stats[root_label, cv2.CC_STAT_HEIGHT]\n",
    "\n",
    "                            root_x = x + root_x_rel\n",
    "                            root_y = y + root_y_rel\n",
    "\n",
    "                            # convert local coords to global\n",
    "                            global_start = (start[0] + y, start[1] + x)\n",
    "                            global_tip   = (tip[0] + y,   tip[1] + x)\n",
    "\n",
    "                            plant_roots.append({\n",
    "                                \"root_label\": root_label,\n",
    "                                \"length\": length,\n",
    "                                \"start\": global_start,  # (row, col)\n",
    "                                \"tip\": global_tip,      # (row, col)\n",
    "                                \"skeleton\": skeleton,\n",
    "                                \"bounding_box\": (root_x, root_y, root_w, root_h)\n",
    "                            })\n",
    "                    except ValueError:\n",
    "                        # Not enough endpoints, skip\n",
    "                        pass\n",
    "\n",
    "            results_by_plant.append({\n",
    "                \"plant_label\": plant_label,\n",
    "                \"plant_area\": plant_area,\n",
    "                \"roots\": plant_roots,\n",
    "                \"bounding_box\": (x, y, w, h)\n",
    "            })\n",
    "\n",
    "    # Flatten all roots\n",
    "    all_roots = [root for plant in results_by_plant for root in plant[\"roots\"]]\n",
    "\n",
    "    # 5 vertical bins across dish\n",
    "    dish_x1, dish_y1, dish_x2, dish_y2 = dish_bbox\n",
    "    dish_width = dish_x2 - dish_x1\n",
    "    segment_width = dish_width / 5.0\n",
    "    plant_bins = []\n",
    "    for i in range(5):\n",
    "        left_bound = dish_x1 + int(round(i * segment_width))\n",
    "        right_bound = dish_x1 + int(round((i + 1) * segment_width))\n",
    "        plant_bins.append((left_bound, right_bound))\n",
    "\n",
    "    # Sort by x-coord of start point (global_start is (row, col), so col=1)\n",
    "    all_roots = sorted(all_roots, key=lambda root: root[\"start\"][1])\n",
    "\n",
    "    # Assign roots to bins\n",
    "    final_results = [{\"plant_id\": i+1, \"length\": 0.0, \"roots\": []} for i in range(5)]\n",
    "    for root in all_roots:\n",
    "        start_x = root[\"start\"][1]\n",
    "        for i, (left_bound, right_bound) in enumerate(plant_bins):\n",
    "            if left_bound <= start_x < right_bound:\n",
    "                final_results[i][\"roots\"].append(root)\n",
    "                if root[\"length\"] > final_results[i][\"length\"]:\n",
    "                    final_results[i][\"length\"] = root[\"length\"]\n",
    "                break\n",
    "\n",
    "    # Rename roots within each bin\n",
    "    for plant_result in final_results:\n",
    "        sorted_roots = sorted(plant_result[\"roots\"], key=lambda r: r[\"length\"], reverse=True)\n",
    "        for idx, root in enumerate(sorted_roots):\n",
    "            root[\"root_id\"] = f\"Root {plant_result['plant_id']}-{idx+1}\"\n",
    "\n",
    "    # Empty bins => length=0.0\n",
    "    for i, plant_result in enumerate(final_results):\n",
    "        if not plant_result[\"roots\"]:\n",
    "            plant_result[\"length\"] = 0.0\n",
    "\n",
    "    return final_results\n",
    "\n",
    "\n",
    "def display_and_save_roots_by_plant(results_by_plant, output_directory, image_basename):\n",
    "    \"\"\"\n",
    "    Display and save skeleton overlays for each plant and its roots.\n",
    "    The output images are named using the original image base name followed by _root_<index>.png\n",
    "    \"\"\"\n",
    "    os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "    for plant in results_by_plant:\n",
    "        for root in plant[\"roots\"]:\n",
    "            root_id = root.get(\"root_id\", \"unknown\")\n",
    "            root_filename = f\"{image_basename}_{root_id}.png\"\n",
    "\n",
    "            x, y, w, h = root[\"bounding_box\"]\n",
    "            skeleton_mask = root['skeleton']\n",
    "\n",
    "            # Create a blank RGB canvas\n",
    "            blank_canvas = np.zeros((h, w, 3), dtype=np.uint8)\n",
    "            # Overlay the skeleton in red channel\n",
    "            # note that 'skeleton_mask' is local: top-left corner = (0,0) in that bounding box\n",
    "            skeleton_overlay = (skeleton_mask * 255).astype(np.uint8)\n",
    "            blank_canvas[:skeleton_mask.shape[0], :skeleton_mask.shape[1], 2] = skeleton_overlay\n",
    "\n",
    "            output_path = os.path.join(output_directory, root_filename)\n",
    "            cv2.imwrite(output_path, blank_canvas)\n",
    "\n",
    "def extract_root_coordinates(final_results):\n",
    "    \"\"\"\n",
    "    Converts 'results_by_plant' into a dictionary of root coordinates\n",
    "    that can be used by an RL pipeline or elsewhere.\n",
    "\n",
    "    final_results is a list of 5 dicts (bins), each with:\n",
    "       {\n",
    "         \"plant_id\": int,\n",
    "         \"length\": float,         # longest root in that bin\n",
    "         \"roots\": [\n",
    "             {\n",
    "               \"root_id\": str,    # e.g., \"Root 1-1\"\n",
    "               \"length\": float,   # length of this root\n",
    "               \"start\": (int, int),  # (row, col)\n",
    "               \"tip\": (int, int),    # (row, col)\n",
    "               ...\n",
    "             },\n",
    "             ...\n",
    "         ]\n",
    "       }\n",
    "    Returns a dictionary, e.g.:\n",
    "       {\n",
    "         \"plant_1\": [\n",
    "            {\n",
    "              \"root_id\": \"Root 1-1\",\n",
    "              \"start\": (row, col),\n",
    "              \"tip\": (row, col),\n",
    "              \"length\": float\n",
    "            },\n",
    "            ...\n",
    "         ],\n",
    "         \"plant_2\": [...],\n",
    "         ...\n",
    "       }\n",
    "    \"\"\"\n",
    "    coords_dict = {}\n",
    "\n",
    "    for plant_data in final_results:\n",
    "        plant_id = plant_data[\"plant_id\"]  # e.g. 1, 2, 3...\n",
    "        plant_key = f\"plant_{plant_id}\"\n",
    "        coords_dict[plant_key] = []\n",
    "        \n",
    "        for root in plant_data[\"roots\"]:\n",
    "            # Grab relevant info\n",
    "            root_id = root.get(\"root_id\", \"unknown_root\")\n",
    "            start_pt = root[\"start\"]  # (row, col)\n",
    "            tip_pt   = root[\"tip\"]    # (row, col)\n",
    "            length   = root[\"length\"]\n",
    "\n",
    "            coords_dict[plant_key].append({\n",
    "                \"root_id\": root_id,\n",
    "                \"start\": start_pt,\n",
    "                \"tip\": tip_pt,\n",
    "                \"length\": length\n",
    "            })\n",
    "\n",
    "    return coords_dict\n",
    "# ----------------------------------------------------------\n",
    "# NEW PIPELINE REQUIREMENT: PLOTTING TIPS ON ORIGINAL IMAGE\n",
    "# ----------------------------------------------------------\n",
    "def plot_tips_on_original_image(original_image_path, final_results, output_path):\n",
    "    \"\"\"\n",
    "    Plots the tip of each root onto the original Petri dish image so we can see if the coordinates\n",
    "    (in global space) are accurate.\n",
    "    - final_results: the data structure returned by isolate_and_measure_roots_by_plant().\n",
    "      final_results is a list of 5 dicts, each with \"roots\" containing global tip coords.\n",
    "    \"\"\"\n",
    "    # Read original image in color\n",
    "    original_img = cv2.imread(original_image_path, cv2.IMREAD_COLOR)\n",
    "    if original_img is None:\n",
    "        raise FileNotFoundError(f\"Could not load original image: {original_image_path}\")\n",
    "\n",
    "    # Loop over each bin (plant_id) and each root\n",
    "    for plant_data in final_results:\n",
    "        for root in plant_data[\"roots\"]:\n",
    "            tip = root[\"tip\"]  # (row, col)\n",
    "            tip_x = tip[1]\n",
    "            tip_y = tip[0]\n",
    "\n",
    "            # Draw a small circle at the tip\n",
    "            cv2.circle(original_img, (tip_x, tip_y), radius=6, color=(0, 0, 255), thickness=-1)\n",
    "\n",
    "            # Optionally, label it with the root_id\n",
    "            root_id = root.get(\"root_id\", \"UnknownRoot\")\n",
    "            cv2.putText(original_img, root_id, (tip_x+8, tip_y),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
    "\n",
    "    # Save the result\n",
    "    cv2.imwrite(output_path, original_img)\n",
    "\n",
    "\n",
    "# ---------------------------------------\n",
    "# MAIN EXECUTION WITH BOTH STEPS\n",
    "# ---------------------------------------\n",
    "def main_pipeline_example():\n",
    "    # 1) Load model\n",
    "    model_path = \"final_modified_model.h5\"\n",
    "    model = load_model(model_path, custom_objects={\"f1_score\": f1_score})\n",
    "\n",
    "    # 2) Initialize the OT2 environment\n",
    "    env = OT2Env(render=True)\n",
    "    image_path = env.get_plate_image()\n",
    "    if not image_path:\n",
    "        raise ValueError(\"Failed to retrieve plate image path from the environment.\")\n",
    "\n",
    "    # 3) Load the grayscale image\n",
    "    original_image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    # 4) Morphological crop\n",
    "    cropped_img, petri_dish_bbox = morphological_petri_dish_crop(original_image)\n",
    "\n",
    "    # 5) Pad\n",
    "    patching_size = 256\n",
    "    padded_image, _ = padder_with_overlap(cropped_img, patching_size)\n",
    "\n",
    "    # 6) Patch\n",
    "    stride = 256\n",
    "    patched, positions = patch_image(padded_image, patch_size=patching_size, stride=stride)\n",
    "\n",
    "    # 7) Predict\n",
    "    predicted = predict_patches(patched, model)\n",
    "\n",
    "    # 8) Unpatch\n",
    "    unpatched = unpatch_image(predicted, positions, padded_image.shape, patch_size=patching_size)\n",
    "\n",
    "    # 9) Reverse crop/padding\n",
    "    final_mask = reverse_padding_and_cropping(unpatched, original_image.shape, petri_dish_bbox)\n",
    "\n",
    "    # 10) Post-process\n",
    "    processed_mask = process_root_mask(final_mask)\n",
    "    skeletonized_mask = skeletonize_mask_skimage(processed_mask, min_size=150)\n",
    "\n",
    "    # 11) Create overlay for quick visualization\n",
    "    overlay = create_overlay(original_image, skeletonized_mask, alpha=0.5)\n",
    "\n",
    "    # 12) Save final mask and overlay\n",
    "    output_dir = \"Final_Masks_Iteration_10\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    base_name = \"plate_image\"\n",
    "\n",
    "    final_mask_path = os.path.join(output_dir, f\"{base_name}_mask.png\")\n",
    "    overlay_path = os.path.join(output_dir, f\"{base_name}_overlay.png\")\n",
    "\n",
    "    cv2.imwrite(final_mask_path, (final_mask * 255).astype(np.uint8))\n",
    "    overlay_bgr = cv2.cvtColor((overlay * 255).astype(np.uint8), cv2.COLOR_RGB2BGR)\n",
    "    cv2.imwrite(overlay_path, overlay_bgr)\n",
    "\n",
    "    print(f\"Saved final mask to {final_mask_path}\")\n",
    "    print(f\"Saved overlay to {overlay_path}\")\n",
    "\n",
    "    # 13) Run isolate & measure on that final mask\n",
    "    results_by_plant = isolate_and_measure_roots_by_plant(\n",
    "        final_mask_path,   # path to the binary mask\n",
    "        min_area=500,\n",
    "        max_horizontal_to_vertical_ratio=0.5,\n",
    "        min_length=10,\n",
    "        dish_bbox=petri_dish_bbox\n",
    "    )\n",
    "\n",
    "    # 14) Save skeleton overlays (debug)\n",
    "    skeleton_output_dir = \"Skeleton_Iteration_10\"\n",
    "    display_and_save_roots_by_plant(results_by_plant, skeleton_output_dir, base_name)\n",
    "\n",
    "    # 15) Plot tips on the *original* image for a final coordinate check\n",
    "    final_tips_plot_path = os.path.join(skeleton_output_dir, f\"{base_name}_tips_plotted.png\")\n",
    "    plot_tips_on_original_image(\n",
    "        original_image_path=image_path,\n",
    "        final_results=results_by_plant,\n",
    "        output_path=final_tips_plot_path\n",
    "    )\n",
    "    print(f\"Plotted root endpoints on original image: {final_tips_plot_path}\")\n",
    "\n",
    "    # 16) Convert the measurement results into a dictionary for RL pipeline\n",
    "    coords_dict = extract_root_coordinates(results_by_plant)\n",
    "    print(\"\\n--- Coordinates Dictionary ---\")\n",
    "    for plant_key, roots_list in coords_dict.items():\n",
    "        print(f\"{plant_key}:\")\n",
    "        for root_info in roots_list:\n",
    "            print(f\"  {root_info}\")\n",
    "    \n",
    "    # Now you can pass 'coords_dict' to your RL pipeline.\n",
    "    # e.g. env.step(coords_dict) or however you incorporate it.\n",
    "    return coords_dict\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    coordinates_dict = main_pipeline_example()\n",
    "    print(coordinates_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to process test_image_1.png: [Errno 2] Unable to synchronously open file (unable to open file: name = 'converted_models/converted_AlexiKehayias_232230_unet_model_Iteration_1_Root_Final_256px.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n",
      "Failed to process test_image_10.png: [Errno 2] Unable to synchronously open file (unable to open file: name = 'converted_models/converted_AlexiKehayias_232230_unet_model_Iteration_1_Root_Final_256px.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n",
      "Failed to process test_image_11.png: [Errno 2] Unable to synchronously open file (unable to open file: name = 'converted_models/converted_AlexiKehayias_232230_unet_model_Iteration_1_Root_Final_256px.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n",
      "Failed to process test_image_12.png: [Errno 2] Unable to synchronously open file (unable to open file: name = 'converted_models/converted_AlexiKehayias_232230_unet_model_Iteration_1_Root_Final_256px.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n",
      "Failed to process test_image_13.png: [Errno 2] Unable to synchronously open file (unable to open file: name = 'converted_models/converted_AlexiKehayias_232230_unet_model_Iteration_1_Root_Final_256px.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n",
      "Failed to process test_image_14.png: [Errno 2] Unable to synchronously open file (unable to open file: name = 'converted_models/converted_AlexiKehayias_232230_unet_model_Iteration_1_Root_Final_256px.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n",
      "Failed to process test_image_15.png: [Errno 2] Unable to synchronously open file (unable to open file: name = 'converted_models/converted_AlexiKehayias_232230_unet_model_Iteration_1_Root_Final_256px.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n",
      "Failed to process test_image_16.png: [Errno 2] Unable to synchronously open file (unable to open file: name = 'converted_models/converted_AlexiKehayias_232230_unet_model_Iteration_1_Root_Final_256px.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n",
      "Failed to process test_image_17.png: [Errno 2] Unable to synchronously open file (unable to open file: name = 'converted_models/converted_AlexiKehayias_232230_unet_model_Iteration_1_Root_Final_256px.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n",
      "Failed to process test_image_18.png: [Errno 2] Unable to synchronously open file (unable to open file: name = 'converted_models/converted_AlexiKehayias_232230_unet_model_Iteration_1_Root_Final_256px.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n",
      "Failed to process test_image_2.png: [Errno 2] Unable to synchronously open file (unable to open file: name = 'converted_models/converted_AlexiKehayias_232230_unet_model_Iteration_1_Root_Final_256px.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n",
      "Failed to process test_image_3.png: [Errno 2] Unable to synchronously open file (unable to open file: name = 'converted_models/converted_AlexiKehayias_232230_unet_model_Iteration_1_Root_Final_256px.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n",
      "Failed to process test_image_4.png: [Errno 2] Unable to synchronously open file (unable to open file: name = 'converted_models/converted_AlexiKehayias_232230_unet_model_Iteration_1_Root_Final_256px.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n",
      "Failed to process test_image_5.png: [Errno 2] Unable to synchronously open file (unable to open file: name = 'converted_models/converted_AlexiKehayias_232230_unet_model_Iteration_1_Root_Final_256px.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n",
      "Failed to process test_image_6.png: [Errno 2] Unable to synchronously open file (unable to open file: name = 'converted_models/converted_AlexiKehayias_232230_unet_model_Iteration_1_Root_Final_256px.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n",
      "Failed to process test_image_7.png: [Errno 2] Unable to synchronously open file (unable to open file: name = 'converted_models/converted_AlexiKehayias_232230_unet_model_Iteration_1_Root_Final_256px.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n",
      "Failed to process test_image_8.png: [Errno 2] Unable to synchronously open file (unable to open file: name = 'converted_models/converted_AlexiKehayias_232230_unet_model_Iteration_1_Root_Final_256px.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n",
      "Failed to process test_image_9.png: [Errno 2] Unable to synchronously open file (unable to open file: name = 'converted_models/converted_AlexiKehayias_232230_unet_model_Iteration_1_Root_Final_256px.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.measure import label, regionprops\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import load_model\n",
    "import tensorflow.keras.backend as K\n",
    "import tensorflow as tf\n",
    "from skimage.morphology import skeletonize\n",
    "import pandas as pd\n",
    "from skimage.morphology import skeletonize\n",
    "from skimage.measure import regionprops\n",
    "import numpy as np\n",
    "\n",
    "# ======================================\n",
    "#           Custom F1 Score Metric\n",
    "# ======================================\n",
    "def f1_score(y_true, y_pred):\n",
    "    y_pred_bin = tf.round(tf.clip_by_value(y_pred, 0, 1))\n",
    "    tp = K.sum(tf.round(y_true * y_pred_bin))\n",
    "    fp = K.sum(tf.round((1 - y_true) * y_pred_bin))\n",
    "    fn = K.sum(tf.round(y_true * (1 - y_pred_bin)))\n",
    "    precision = tp / (tp + fp + K.epsilon())\n",
    "    recall = tp / (tp + fn + K.epsilon())\n",
    "    f1 = 2 * precision * recall / (precision + recall + K.epsilon())\n",
    "    return f1\n",
    "\n",
    "\n",
    "# ======================================\n",
    "#       Image Preprocessing\n",
    "# ======================================\n",
    "def combine_edges_and_threshold(gray_img):\n",
    "    \"\"\"\n",
    "    Combine Canny edges and a binary threshold for better contour detection.\n",
    "    \"\"\"\n",
    "    gray_img_uint8 = (gray_img * 255).astype(np.uint8)\n",
    "    detected_edges = cv2.Canny(gray_img_uint8, 50, 150)\n",
    "    _, thresholded_img = cv2.threshold(gray_img_uint8, 100, 255, cv2.THRESH_BINARY)\n",
    "    overlay = cv2.addWeighted(detected_edges, 0.6, thresholded_img, 0.4, 0)\n",
    "    return overlay\n",
    "\n",
    "\n",
    "def locate_main_contour(img_shape, edge_img):\n",
    "    \"\"\"\n",
    "    Find the bounding box of the largest external contour.\n",
    "    \"\"\"\n",
    "    contours, _ = cv2.findContours(edge_img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    if not contours:\n",
    "        return 0, 0, img_shape[1], img_shape[0]\n",
    "    big_contour = max(contours, key=cv2.contourArea)\n",
    "    x, y, w, h = cv2.boundingRect(big_contour)\n",
    "    return x, y, w, h\n",
    "\n",
    "\n",
    "def square_crop(gray_img, bounding_box, buffer_percent=0.04):\n",
    "    \"\"\"\n",
    "    Crop around the main contour to produce a roughly square region.\n",
    "    \"\"\"\n",
    "    x, y, width, height = bounding_box\n",
    "    side_len = max(width, height)\n",
    "    center_x = x + width // 2\n",
    "    center_y = y + height // 2\n",
    "    pad = int(side_len * buffer_percent)\n",
    "    top_edge = max(0, center_y - side_len // 2 - pad)\n",
    "    bottom_edge = center_y + side_len // 2 + pad\n",
    "    left_edge = max(0, center_x - side_len // 2 - pad)\n",
    "    right_edge = center_x + side_len // 2 + pad\n",
    "    return gray_img[top_edge:bottom_edge, left_edge:right_edge]\n",
    "\n",
    "\n",
    "\n",
    "# ======================================\n",
    "#       Patch-based Segmentation\n",
    "# ======================================\n",
    "def segment_image_in_patches(segm_model, gray_img, patch_size=256):\n",
    "    \"\"\"\n",
    "    Perform patch-based segmentation and stitch the result into a full mask.\n",
    "    \"\"\"\n",
    "    border_size = 1\n",
    "    # Pad the image to handle edges\n",
    "    padded = cv2.copyMakeBorder(\n",
    "        gray_img, border_size, border_size, border_size, border_size,\n",
    "        cv2.BORDER_CONSTANT, value=0\n",
    "    )\n",
    "\n",
    "    patch_list = []\n",
    "    coords_list = []\n",
    "    h, w = padded.shape\n",
    "\n",
    "    # Extract patches\n",
    "    for row_start in range(0, h, patch_size):\n",
    "        for col_start in range(0, w, patch_size):\n",
    "            patch = padded[row_start:row_start + patch_size, col_start:col_start + patch_size]\n",
    "            if patch.shape[0] < patch_size or patch.shape[1] < patch_size:\n",
    "                patch_full = np.zeros((patch_size, patch_size), dtype=np.float32)\n",
    "                patch_full[:patch.shape[0], :patch.shape[1]] = patch\n",
    "                patch = patch_full\n",
    "\n",
    "            patch_list.append(patch)\n",
    "            coords_list.append((row_start, col_start))\n",
    "\n",
    "    # Model inference\n",
    "    batch_input = np.array(patch_list)[..., np.newaxis]\n",
    "    batch_output = segm_model.predict(batch_input)\n",
    "\n",
    "    # Reassemble\n",
    "    complete_mask = np.zeros_like(padded, dtype=np.float32)\n",
    "    for idx, (r, c) in enumerate(coords_list):\n",
    "        piece_height, piece_width = padded[r:r + patch_size, c:c + patch_size].shape\n",
    "        full_prediction = batch_output[idx].squeeze()[:piece_height, :piece_width]\n",
    "        complete_mask[r:r + piece_height, c:c + piece_width] = full_prediction\n",
    "\n",
    "    # Remove padding\n",
    "    return complete_mask[border_size:-border_size, border_size:-border_size]\n",
    "\n",
    "\n",
    "# ====================================================\n",
    "#   Post-processing of Predictions-Regions of Interest\n",
    "# ====================================================\n",
    "def refine_mask_for_shoots(predicted_mask, min_pixels=1):\n",
    "    \"\"\"\n",
    "    Refine the mask for shoot predictions using morphological closing and connected component filtering.\n",
    "    \"\"\"\n",
    "    bin_mask = (predicted_mask > 0.5).astype(np.uint8)\n",
    "    shape_kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (20, 20))\n",
    "    closed_mask = cv2.morphologyEx(bin_mask, cv2.MORPH_CLOSE, shape_kernel)\n",
    "\n",
    "    label_img = label(closed_mask)\n",
    "    refined = np.zeros_like(closed_mask, dtype=np.uint8)\n",
    "    for props in regionprops(label_img):\n",
    "        if props.area >= min_pixels:\n",
    "            refined[label_img == props.label] = 1\n",
    "    return refined\n",
    "\n",
    "\n",
    "def refine_mask_for_roots(predicted_mask, min_pixels=1):\n",
    "    \"\"\"\n",
    "    Refine the mask for root predictions using additional morphological operations to improve connectivity.\n",
    "    \"\"\"\n",
    "    # Binarize the mask\n",
    "    bin_mask = (predicted_mask > 0.5).astype(np.uint8)\n",
    "\n",
    "    # Step 1: Dilate to connect nearby segments\n",
    "    dilation_kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (14, 14)) \n",
    "    dilated_mask = cv2.dilate(bin_mask, dilation_kernel, iterations=1)\n",
    "\n",
    "    # Step 2: Morphological closing to fill small gaps\n",
    "    shape_kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (10, 10))\n",
    "    closed_mask = cv2.morphologyEx(dilated_mask, cv2.MORPH_CLOSE, shape_kernel)\n",
    "\n",
    "    # Step 3: Retain only connected components with a minimum pixel size\n",
    "    label_img = label(closed_mask)\n",
    "    refined = np.zeros_like(closed_mask, dtype=np.uint8)\n",
    "    for props in regionprops(label_img):\n",
    "        if props.area >= min_pixels:\n",
    "            refined[label_img == props.label] = 1\n",
    "\n",
    "    return refined\n",
    "\n",
    "\n",
    "def extract_bounding_boxes_for_shoots(mask, min_area=1):\n",
    "    \"\"\"\n",
    "    Extract bounding boxes for shoot regions in a binary mask.\n",
    "    \"\"\"\n",
    "    labeled_mask = label(mask)\n",
    "    bboxes = []\n",
    "    for region in regionprops(labeled_mask):\n",
    "        if region.area >= min_area:\n",
    "            minr, minc, maxr, maxc = region.bbox\n",
    "            bboxes.append((minc, minr, maxc - minc, maxr - minr))  # (x, y, w, h)\n",
    "    return bboxes\n",
    "\n",
    "\n",
    "def extract_bounding_boxes_for_roots(mask, min_area=1):\n",
    "    \"\"\"\n",
    "    Extract bounding boxes for root regions in a binary mask.\n",
    "    \"\"\"\n",
    "    labeled_mask = label(mask)\n",
    "    bboxes = []\n",
    "    for region in regionprops(labeled_mask):\n",
    "        if region.area >= min_area:\n",
    "            minr, minc, maxr, maxc = region.bbox\n",
    "            bboxes.append((minc, minr, maxc - minc, maxr - minr))  # (x, y, w, h)\n",
    "    return bboxes\n",
    "\n",
    "\n",
    "def normalize_image(image):\n",
    "    \"\"\"\n",
    "    Normalize the image to the range [0, 1].\n",
    "    \"\"\"\n",
    "    return image / 255.0\n",
    "\n",
    "\n",
    "def apply_shoot_roi_mask(mask, roi):\n",
    "    \"\"\"\n",
    "    Apply a mask to keep only the region of interest (ROI) for shoot predictions.\n",
    "    \"\"\"\n",
    "    x, y, w, h = roi\n",
    "    roi_mask = np.zeros_like(mask, dtype=np.uint8)\n",
    "    roi_mask[y:y + h, x:x + w] = 1\n",
    "    return mask * roi_mask\n",
    "\n",
    "\n",
    "def calculate_roi_with_margin(image, roi_height_fraction=0.25, top_margin_fraction=0.1, \n",
    "                              inner_margin_fraction=0.09, outer_margin_fraction=0.32):\n",
    "    img_height, img_width = image.shape\n",
    "\n",
    "    # Detect transitions (boundaries) dynamically\n",
    "    left_boundary = next(\n",
    "        (i for i in range(img_width // 2) if image[:, i].mean() < 200), 10\n",
    "    )\n",
    "    right_boundary = next(\n",
    "        (i for i in range(img_width - 1, img_width // 2, -1) if image[:, i].mean() < 200),\n",
    "        img_width - 10,\n",
    "    )\n",
    "\n",
    "    # Expand the left boundary dynamically\n",
    "    inner_margin = int(img_width * inner_margin_fraction)\n",
    "    x = max(left_boundary - 20 + inner_margin, 0)  # Adjust left boundary\n",
    "    \n",
    "    # Adjust ROI width\n",
    "    outer_margin = int(img_width * outer_margin_fraction)\n",
    "    width = max(right_boundary - x - outer_margin, 0)\n",
    "\n",
    "    # Define top and height of the ROI\n",
    "    y = int(img_height * top_margin_fraction)\n",
    "    height = int(img_height * roi_height_fraction)\n",
    "\n",
    "    return (x, y, width, height)\n",
    "\n",
    "\n",
    "\n",
    "# ======================================\n",
    "#    Zone-Based Filtering & RSA\n",
    "# ======================================\n",
    "def get_zone_from_bbox(bbox, img_width):\n",
    "    \"\"\"\n",
    "    Determine which zone a bounding box belongs to (0 to 4).\n",
    "    \"\"\"\n",
    "    x, y, w, h = bbox\n",
    "    zone_width = img_width // 5  # 5 zones\n",
    "    center_x = x + w / 2.0\n",
    "\n",
    "    for zone in range(5):\n",
    "        if center_x < (zone + 1) * zone_width:\n",
    "            return zone\n",
    "    return 4\n",
    "\n",
    "\n",
    "def filter_root_bboxes_in_zone(root_bboxes, zone, img_width):\n",
    "    \"\"\"\n",
    "    Filter root bounding boxes that belong to a specific zone (by center_x).\n",
    "    \"\"\"\n",
    "    zone_bboxes = []\n",
    "    zone_w = img_width // 5\n",
    "    zone_start_x = zone * zone_w\n",
    "    zone_end_x = zone_start_x + zone_w\n",
    "\n",
    "    for bbox in root_bboxes:\n",
    "        x, y, w, h = bbox\n",
    "        center_x = x + w / 2.0\n",
    "        if zone_start_x <= center_x < zone_end_x:\n",
    "            zone_bboxes.append(bbox)\n",
    "    return zone_bboxes\n",
    "\n",
    "def filter_primary_root_in_each_zone(root_bboxes, img_width):\n",
    "    primary_roots_by_zone = {}\n",
    "    for zone in range(5):\n",
    "        zone_bboxes = filter_root_bboxes_in_zone(root_bboxes, zone, img_width)\n",
    "        if zone_bboxes:\n",
    "            # Add a tolerance to include partially overlapping boxes\n",
    "            largest_bbox = max(zone_bboxes, key=lambda bbox: bbox[2] * bbox[3])\n",
    "            if zone == 0:\n",
    "                # Include small left boxes\n",
    "                largest_bbox = max(zone_bboxes, key=lambda bbox: bbox[2] * bbox[3] + bbox[0])\n",
    "            primary_roots_by_zone[zone] = largest_bbox\n",
    "    return primary_roots_by_zone\n",
    "\n",
    "def divide_bboxes_into_zones(bboxes, img_width):\n",
    "    zones = {i: [] for i in range(5)}\n",
    "    zone_width = img_width / 5\n",
    "    zone_boundaries = [(i * zone_width, (i + 1) * zone_width) for i in range(5)]\n",
    "\n",
    "    for bbox in bboxes:\n",
    "        x, y, w, h = bbox\n",
    "        center_x = x + w / 2\n",
    "        for i, (zone_start, zone_end) in enumerate(zone_boundaries):\n",
    "            if zone_start - 10 <= center_x < zone_end + 10:  # Add tolerance\n",
    "                zones[i].append(bbox)\n",
    "                break\n",
    "\n",
    "    return zones\n",
    "\n",
    "def filter_largest_shoot_bbox(bboxes, shoot_roi):\n",
    "    \"\"\"\n",
    "    Retain only the largest shoot bounding box within the shoot ROI.\n",
    "    \"\"\"\n",
    "    roi_x, roi_y, roi_w, roi_h = shoot_roi\n",
    "    filtered_bboxes = []\n",
    "\n",
    "    for bbox in bboxes:\n",
    "        x, y, w, h = bbox\n",
    "        # Check intersection with the ROI\n",
    "        if x + w > roi_x and x < roi_x + roi_w and y + h > roi_y and y < roi_y + roi_h:\n",
    "            filtered_bboxes.append(bbox)\n",
    "\n",
    "    if not filtered_bboxes:\n",
    "        return None\n",
    "\n",
    "    largest_bbox = max(filtered_bboxes, key=lambda bx: bx[2] * bx[3])\n",
    "    return largest_bbox\n",
    "\n",
    "\n",
    "def filter_root_bboxes_in_zones_with_priority(bboxes, zones, min_area_ratio=0.1):\n",
    "    \"\"\"\n",
    "    Retain the largest root bounding box in each zone and include smaller ones if above area threshold.\n",
    "    \"\"\"\n",
    "    filtered_bboxes = []\n",
    "\n",
    "    for zone, zone_bboxes in zones.items():\n",
    "        if zone_bboxes:\n",
    "            largest_bbox = max(zone_bboxes, key=lambda bbox: bbox[2] * bbox[3])\n",
    "            largest_area = largest_bbox[2] * largest_bbox[3]\n",
    "            filtered_bboxes.append(largest_bbox)\n",
    "            for bbox in zone_bboxes:\n",
    "                if bbox != largest_bbox:\n",
    "                    area = bbox[2] * bbox[3]\n",
    "                    if area >= largest_area * min_area_ratio:\n",
    "                        filtered_bboxes.append(bbox)\n",
    "\n",
    "    return filtered_bboxes\n",
    "\n",
    "\n",
    "def filter_primary_roots_by_region(filtered_root_bboxes, root_zones):\n",
    "    \"\"\"\n",
    "    Pick the largest bounding box in each zone as the 'primary root'.\n",
    "    \"\"\"\n",
    "    primary_roots_by_region = {}\n",
    "    for zone in range(5):\n",
    "        if zone in root_zones and root_zones[zone]:\n",
    "            largest_bbox = max(root_zones[zone], key=lambda bbox: bbox[2] * bbox[3])\n",
    "            primary_roots_by_region[zone] = largest_bbox\n",
    "            print(f\"Zone {zone}: Selected Primary Root: {largest_bbox}\")\n",
    "        else:\n",
    "            primary_roots_by_region[zone] = None\n",
    "            print(f\"Zone {zone}: No roots found.\")\n",
    "    return primary_roots_by_region\n",
    "\n",
    "\n",
    "def calculate_endpoint_distance_with_tip(skeleton):\n",
    "    \"\"\"\n",
    "    Calculate the distance between the first and last endpoints of a skeleton\n",
    "    and return the coordinates of these endpoints.\n",
    "    \"\"\"\n",
    "    # Find endpoints: pixels with exactly one neighbor\n",
    "    endpoint_coords = []\n",
    "    for y in range(1, skeleton.shape[0] - 1):\n",
    "        for x in range(1, skeleton.shape[1] - 1):\n",
    "            if skeleton[y, x]:  # Check if the pixel is part of the skeleton\n",
    "                neighbors = np.sum(skeleton[y - 1:y + 2, x - 1:x + 2]) - 1\n",
    "                if neighbors == 1:  # Endpoint has only one neighbor\n",
    "                    endpoint_coords.append((y, x))\n",
    "\n",
    "    # If there are at least two endpoints, calculate distance\n",
    "    if len(endpoint_coords) >= 2:\n",
    "        p1, p2 = endpoint_coords[0], endpoint_coords[-1]\n",
    "        distance = np.sqrt((p1[0] - p2[0])**2 + (p1[1] - p2[1])**2)\n",
    "        return int(distance), p2  # Return distance and the tip coordinate (last endpoint)\n",
    "\n",
    "    # If no valid endpoints, return 0 and None\n",
    "    return 0, None\n",
    "\n",
    "def extract_region_masks_with_tips(primary_roots_by_region, root_mask, cropped_img):\n",
    "    \"\"\"\n",
    "    Extract region masks for the primary roots, calculate their skeletonized lengths,\n",
    "    and return their tip coordinates.\n",
    "    \"\"\"\n",
    "    skeletonized_roots_by_region = {}\n",
    "    root_lengths_by_zone = {}\n",
    "    root_tips_by_zone = {}\n",
    "\n",
    "    for zone in range(5):\n",
    "        if zone in primary_roots_by_region and primary_roots_by_region[zone] is not None:\n",
    "            x, y, w, h = primary_roots_by_region[zone]\n",
    "            region_mask = root_mask[y:y + h, x:x + w]\n",
    "            region_cropped_img = cropped_img[y:y + h, x:x + w]\n",
    "\n",
    "            # Skeletonize\n",
    "            skeleton = skeletonize(region_mask)\n",
    "            skeletonized_roots_by_region[zone] = (skeleton, region_cropped_img)\n",
    "\n",
    "            # Calculate the endpoint distance and the tip coordinate\n",
    "            endpoint_distance, tip_coord = calculate_endpoint_distance_with_tip(skeleton)\n",
    "            root_lengths_by_zone[zone] = endpoint_distance\n",
    "\n",
    "            # Convert tip coordinates to global image coordinates\n",
    "            if tip_coord:\n",
    "                global_tip_coord = (tip_coord[1] + x, tip_coord[0] + y)  # (x, y) in global coordinates\n",
    "                root_tips_by_zone[zone] = global_tip_coord\n",
    "\n",
    "        else:\n",
    "            skeletonized_roots_by_region[zone] = None\n",
    "            root_lengths_by_zone[zone] = 0\n",
    "            root_tips_by_zone[zone] = None\n",
    "\n",
    "    return skeletonized_roots_by_region, root_lengths_by_zone, root_tips_by_zone\n",
    "\n",
    "def visualize_predictions_with_tips(image, shoots, roots, zones, roi, root_tips, title):\n",
    "    \"\"\"\n",
    "    Visualize bounding boxes for shoots/roots plus vertical zone divisions, ROI rectangle,\n",
    "    and plot primary root tips.\n",
    "    \"\"\"\n",
    "    image_uint8 = (image * 255).astype(np.uint8)\n",
    "    overlay = cv2.cvtColor(image_uint8, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    img_height, img_width = image.shape\n",
    "    zone_width = img_width // 5\n",
    "\n",
    "    # Draw zone lines\n",
    "    for i in range(1, 5):\n",
    "        cv2.line(overlay, (i * zone_width, 0), (i * zone_width, img_height), (255, 255, 0), 2)\n",
    "\n",
    "    # Shoots in green\n",
    "    for bbox in shoots:\n",
    "        x, y, w, h = bbox\n",
    "        cv2.rectangle(overlay, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "    # Roots in red\n",
    "    for bbox in roots:\n",
    "        x, y, w, h = bbox\n",
    "        cv2.rectangle(overlay, (x, y), (x + w, y + h), (0, 0, 255), 2)\n",
    "\n",
    "    # ROI in blue\n",
    "    roi_x, roi_y, roi_w, roi_h = roi\n",
    "    cv2.rectangle(overlay, (roi_x, roi_y), (roi_x + roi_w, roi_y + roi_h), (255, 0, 0), 2)\n",
    "\n",
    "    # Annotate zones\n",
    "    for zone in range(5):\n",
    "        zone_bboxes = zones.get(zone, [])\n",
    "        for bbox in zone_bboxes:\n",
    "            x, y, w, h = bbox\n",
    "            cx = x + w // 2\n",
    "            cy = y + h // 2\n",
    "            cv2.putText(overlay, f\"Z{zone}\", (int(cx), int(cy)),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 1)\n",
    "\n",
    "    # Plot root tips in magenta\n",
    "    for zone, tip in root_tips.items():\n",
    "        if tip:\n",
    "            cv2.circle(overlay, tip, 5, (255, 0, 255), -1)\n",
    "\n",
    "    plt.figure(figsize=(12, 12))\n",
    "    plt.imshow(overlay[..., ::-1])  # Convert BGR to RGB\n",
    "    plt.title(title)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "# ======================================\n",
    "#   Visualization Functions\n",
    "# ======================================\n",
    "def save_and_visualize_predicted_mask(mask, output_path=None, title=\"Predicted Mask\"):\n",
    "    \"\"\"\n",
    "    Save and visualize the predicted mask.\n",
    "    Args:\n",
    "        mask (numpy array): The predicted mask to be visualized.\n",
    "        output_path (str, optional): Path to save the mask. If None, it won't save.\n",
    "        title (str): Title for the visualization.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(mask, cmap=\"gray\")\n",
    "    plt.title(title)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "def visualize_predictions_with_roi(image, shoots, roots, roi, title):\n",
    "    \"\"\"\n",
    "    Visualize predictions with bounding boxes and an ROI rectangle.\n",
    "    Shoot boxes in green, root boxes in red, and ROI in blue.\n",
    "    \"\"\"\n",
    "    # Convert the input image to uint8\n",
    "    image_uint8 = (image * 255).astype(np.uint8)\n",
    "\n",
    "    # Convert grayscale to BGR\n",
    "    overlay = cv2.cvtColor(image_uint8, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    # Draw shoot bounding boxes in green\n",
    "    for bbox in shoots:\n",
    "        x, y, w, h = bbox\n",
    "        cv2.rectangle(overlay, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "    # Draw root bounding boxes in red\n",
    "    for bbox in roots:\n",
    "        x, y, w, h = bbox\n",
    "        cv2.rectangle(overlay, (x, y), (x + w, y + h), (0, 0, 255), 2)\n",
    "\n",
    "    # Draw the ROI rectangle in blue\n",
    "    roi_x, roi_y, roi_w, roi_h = roi\n",
    "    cv2.rectangle(overlay, (roi_x, roi_y), (roi_x + roi_w, roi_y + roi_h), (255, 0, 0), 2)\n",
    "\n",
    "    # Display the image\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(overlay[..., ::-1])  # Convert BGR to RGB for display\n",
    "    plt.title(title)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def visualize_skeletonized_roots_by_zone(skeletonized_roots_by_zone, title):\n",
    "    \"\"\"\n",
    "    Visualize the skeletonized primary roots for each zone (0 to 4) in subplots.\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(1, 5, figsize=(20, 5))\n",
    "    fig.suptitle(title, fontsize=16)\n",
    "\n",
    "    for zone in range(5):\n",
    "        ax = axes[zone]\n",
    "        if zone in skeletonized_roots_by_zone:\n",
    "            skeleton, region_cropped_img = skeletonized_roots_by_zone[zone]\n",
    "            overlay = cv2.cvtColor((region_cropped_img * 255).astype(np.uint8), cv2.COLOR_GRAY2BGR)\n",
    "            # Overlay the skeleton in red\n",
    "            overlay[skeleton > 0] = [255, 0, 0]\n",
    "            ax.imshow(overlay)\n",
    "            ax.set_title(f\"Zone {zone}\")\n",
    "        else:\n",
    "            ax.imshow(np.zeros((100, 100)), cmap=\"gray\")\n",
    "            ax.set_title(f\"Zone {zone} (No root)\")\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def visualize_predictions_with_zones(image, shoots, roots, zones, roi, title):\n",
    "    \"\"\"\n",
    "    Visualize bounding boxes for shoots/roots plus vertical zone divisions and ROI rectangle.\n",
    "    \"\"\"\n",
    "    image_uint8 = (image * 255).astype(np.uint8)\n",
    "    overlay = cv2.cvtColor(image_uint8, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    img_height, img_width = image.shape\n",
    "    zone_width = img_width // 5\n",
    "\n",
    "    # Draw zone lines\n",
    "    for i in range(1, 5):\n",
    "        cv2.line(overlay, (i * zone_width, 0), (i * zone_width, img_height), (255, 255, 0), 2)\n",
    "\n",
    "    # Shoots in green\n",
    "    for bbox in shoots:\n",
    "        x, y, w, h = bbox\n",
    "        cv2.rectangle(overlay, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "    # Roots in red\n",
    "    for bbox in roots:\n",
    "        x, y, w, h = bbox\n",
    "        cv2.rectangle(overlay, (x, y), (x + w, y + h), (0, 0, 255), 2)\n",
    "\n",
    "    # ROI in blue\n",
    "    roi_x, roi_y, roi_w, roi_h = roi\n",
    "    cv2.rectangle(overlay, (roi_x, roi_y), (roi_x + roi_w, roi_y + roi_h), (255, 0, 0), 2)\n",
    "\n",
    "    # Annotate zones\n",
    "    for zone in range(5):\n",
    "        zone_bboxes = zones.get(zone, [])\n",
    "        for bbox in zone_bboxes:\n",
    "            x, y, w, h = bbox\n",
    "            cx = x + w // 2\n",
    "            cy = y + h // 2\n",
    "            cv2.putText(overlay, f\"Z{zone}\", (int(cx), int(cy)),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 1)\n",
    "\n",
    "    for zone, bxs in zones.items():\n",
    "        print(f\"Zone {zone}: {len(bxs)} bounding boxes\")  # Debug\n",
    "\n",
    "    plt.figure(figsize=(12, 12))\n",
    "    plt.imshow(overlay[..., ::-1])\n",
    "    plt.title(title)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "def display_skeletonized_root_masks(cropped_img, root_mask, title=\"Skeletonized Root Mask\"):\n",
    "    \"\"\"\n",
    "    Display the skeleton overlay (red) in place of the predicted root mask.\n",
    "    Left subplot: original cropped image (grayscale).\n",
    "    Right subplot: overlay of the skeleton on grayscale.\n",
    "    \"\"\"\n",
    "    # Skeletonize the binarized root_mask\n",
    "    skeleton = skeletonize(root_mask > 0)\n",
    "\n",
    "    # Prepare overlay\n",
    "    cropped_img_normalized = (cropped_img * 255).astype(np.uint8)\n",
    "    overlay = cv2.cvtColor(cropped_img_normalized, cv2.COLOR_GRAY2BGR)\n",
    "    overlay[skeleton > 0] = [0, 0, 255]  # Red color for skeleton\n",
    "\n",
    "    # Plot side by side\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(cropped_img, cmap=\"gray\")\n",
    "    plt.title(\"Cropped Grayscale Image\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(root_mask, cmap=\"gray\")\n",
    "    plt.title(\"Cropped Grayscale Image\")\n",
    "    plt.axis(\"off\")\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(overlay[..., ::-1])  # BGR -> RGB\n",
    "    plt.title(title)\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def visualize_skeletonized_roots_with_lengths(skeletonized_roots_by_region, root_lengths_by_zone, title):\n",
    "    \"\"\"\n",
    "    Display each zone's cropped region with skeleton overlay, also showing length.\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(1, 5, figsize=(20, 5))\n",
    "    fig.suptitle(title, fontsize=16)\n",
    "\n",
    "    for zone in range(5):\n",
    "        ax = axes[zone]\n",
    "        if zone in skeletonized_roots_by_region and skeletonized_roots_by_region[zone] is not None:\n",
    "            skeleton, region_cropped_img = skeletonized_roots_by_region[zone]\n",
    "            overlay = cv2.cvtColor((region_cropped_img * 255).astype(np.uint8), cv2.COLOR_GRAY2BGR)\n",
    "            overlay[skeleton > 0] = [255, 0, 0]  # Red for skeleton\n",
    "\n",
    "            ax.imshow(overlay)\n",
    "            root_length = root_lengths_by_zone.get(zone, 0)\n",
    "            ax.set_title(f\"Zone {zone}\\nLength: {root_length} pixels\")\n",
    "        else:\n",
    "            ax.imshow(np.zeros((100, 100)), cmap=\"gray\")\n",
    "            ax.set_title(f\"Zone {zone}\\nLength: 0 px\")\n",
    "\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ----------------------Advanced ROI-------------------------\n",
    "def calculate_zone_boundaries_within_roi(shoot_roi, num_zones, img_width):\n",
    "    \"\"\"\n",
    "    Calculate zone boundaries within the shoot ROI (x splits into num_zones).\n",
    "    \"\"\"\n",
    "    roi_x, roi_y, roi_w, roi_h = shoot_roi\n",
    "    zone_width = roi_w / num_zones\n",
    "    zones = [\n",
    "        (roi_x + i * zone_width, roi_x + (i + 1) * zone_width, roi_y, roi_y + roi_h)\n",
    "        for i in range(num_zones)\n",
    "    ]\n",
    "    return zones\n",
    "\n",
    "\n",
    "def assign_roots_to_zones_within_roi(root_bboxes, zones):\n",
    "    assigned_roots = {i: [] for i in range(len(zones))}\n",
    "    for i, (zone_start_x, zone_end_x, zone_start_y, zone_end_y) in enumerate(zones):\n",
    "        for bbox in root_bboxes:\n",
    "            x, y, w, h = bbox\n",
    "            cx = x + w / 2.0\n",
    "            if (zone_start_x <= cx < zone_end_x) or (i == 0 and x < zone_start_x + 10):\n",
    "                assigned_roots[i].append(bbox)\n",
    "    return assigned_roots\n",
    "\n",
    "\n",
    "\n",
    "def select_primary_root_with_extensions(root_bboxes, shoot_roi, zones, img_width):\n",
    "    \"\"\"\n",
    "    1. Filter bounding boxes to those that start in the shoot ROI\n",
    "       (top edge within ROI's vertical extent + some horizontal overlap).\n",
    "    2. In each zone, pick the bounding box with the largest area.\n",
    "    3. Expand that bounding box by merging any other bounding boxes \n",
    "       that overlap it (based on bounding-box overlap, not center).\n",
    "    4. Return the final expanded bounding box for each zone.\n",
    "    \"\"\"\n",
    "\n",
    "    def boxes_overlap(boxA, boxB):\n",
    "        \"\"\"\n",
    "        Check if two bounding boxes overlap.\n",
    "        boxA, boxB: [xmin, ymin, xmax, ymax]\n",
    "        Returns True if they overlap.\n",
    "        \"\"\"\n",
    "        return not (\n",
    "            boxB[0] > boxA[2] + 10 or  # boxB is entirely to the right of boxA\n",
    "            boxB[2] < boxA[0] - 10 or  # boxB is entirely to the left of boxA\n",
    "            boxB[1] > boxA[3] + 10 or  # boxB is entirely below boxA\n",
    "            boxB[3] < boxA[1] - 10     # boxB is entirely above boxA\n",
    "        )\n",
    "\n",
    "    primary_roots_by_zone = {i: None for i in range(len(zones))}\n",
    "    roi_x, roi_y, roi_w, roi_h = shoot_roi\n",
    "\n",
    "    # Step 1: Pick a \"primary\" root bbox in each zone (i.e., the largest one that starts in the ROI).\n",
    "    for bbox in root_bboxes:\n",
    "        x, y, w, h = bbox\n",
    "        area = w * h\n",
    "\n",
    "        # Check if the bbox starts in the shoot ROI (top edge within ROI vertical extent)\n",
    "        within_top = (y >= roi_y) and (y < roi_y + roi_h)\n",
    "        overlaps_horizontally = ((x + w) > roi_x) and (x < roi_x + roi_w)\n",
    "        if not (within_top and overlaps_horizontally):\n",
    "            continue\n",
    "\n",
    "        # Assign this bbox to the zone based on its center_x\n",
    "        cx = x + w / 2.0\n",
    "        for zone_idx, (zsx, zex, zsy, zey) in enumerate(zones):\n",
    "            if (zsx <= cx < zex) or (zone_idx == 0 and x < zsx + 10):  # Allow for overlap tolerance\n",
    "                if (\n",
    "                    primary_roots_by_zone[zone_idx] is None\n",
    "                    or area > primary_roots_by_zone[zone_idx]['area']\n",
    "                ):\n",
    "                    primary_roots_by_zone[zone_idx] = {\n",
    "                        'bbox': bbox,\n",
    "                        'area': area\n",
    "                    }\n",
    "                break\n",
    "\n",
    "    # Step 2: Expand each zone's bounding box by merging any overlapping bounding boxes.\n",
    "    for zone_idx, root_info in primary_roots_by_zone.items():\n",
    "        if root_info is None:\n",
    "            continue\n",
    "        x, y, w, h = root_info['bbox']\n",
    "        total_bbox = [x, y, x + w, y + h]  # [xmin, ymin, xmax, ymax]\n",
    "\n",
    "        # Merge all other bounding boxes that overlap the current bounding box\n",
    "        for bbox in root_bboxes:\n",
    "            ox, oy, ow, oh = bbox\n",
    "            other_box = [ox, oy, ox + ow, oy + oh]\n",
    "\n",
    "            # If they overlap, expand the total_bbox to include the other box\n",
    "            if boxes_overlap(total_bbox, other_box):\n",
    "                total_bbox[0] = min(total_bbox[0], other_box[0])\n",
    "                total_bbox[1] = min(total_bbox[1], other_box[1])\n",
    "                total_bbox[2] = max(total_bbox[2], other_box[2])\n",
    "                total_bbox[3] = max(total_bbox[3], other_box[3])\n",
    "\n",
    "        # Convert [xmin, ymin, xmax, ymax] back to (x, y, w, h)\n",
    "        final_xmin, final_ymin, final_xmax, final_ymax = total_bbox\n",
    "        final_w = final_xmax - final_xmin\n",
    "        final_h = final_ymax - final_ymin\n",
    "        final_area = final_w * final_h\n",
    "\n",
    "        # Update the zone's bounding-box info\n",
    "        root_info['extended_bbox'] = (final_xmin, final_ymin, final_w, final_h)\n",
    "        root_info['total_area'] = final_area\n",
    "\n",
    "    return primary_roots_by_zone\n",
    "\n",
    "# ======================================\n",
    "#   Main Pipeline with Visualization\n",
    "# ======================================\n",
    "\n",
    "def main_pipeline_with_dual_shoot_models_and_tips(root_model1_path, root_model2_path, shoot_model1_path, shoot_model2_path, data_dir, visualize=False):\n",
    "    # Load models\n",
    "    root_model1 = load_model(root_model1_path, compile=False)\n",
    "    root_model2 = load_model(root_model2_path, compile=False)\n",
    "    shoot_model1 = load_model(shoot_model1_path, compile=False)\n",
    "    shoot_model2 = load_model(shoot_model2_path, compile=False)\n",
    "\n",
    "    # Load image (grayscale)\n",
    "    original_image = cv2.imread(data_dir, cv2.IMREAD_GRAYSCALE)\n",
    "    image_height, image_width = original_image.shape\n",
    "\n",
    "    normalized_image = original_image / 255.0\n",
    "\n",
    "    # Preprocess, find bounding box, and crop\n",
    "    edges = combine_edges_and_threshold(normalized_image)\n",
    "    bbox = locate_main_contour(normalized_image.shape, edges)\n",
    "    cropped_img = square_crop(normalized_image, bbox)\n",
    "\n",
    "    # Calculate shoot ROI\n",
    "    shoot_roi = calculate_roi_with_margin(\n",
    "        image=original_image,\n",
    "        roi_height_fraction=0.15,\n",
    "        top_margin_fraction=0.1,\n",
    "        inner_margin_fraction=0.09,\n",
    "        outer_margin_fraction=0.35\n",
    "    )\n",
    "\n",
    "    # Segment shoots using both models\n",
    "    shoot_mask1 = segment_image_in_patches(shoot_model1, cropped_img)\n",
    "    shoot_mask2 = segment_image_in_patches(shoot_model2, cropped_img)\n",
    "\n",
    "    # Combine shoot predictions \n",
    "    combined_shoot_mask = (shoot_mask1 + shoot_mask2)\n",
    "\n",
    "    # Refine the combined shoot mask\n",
    "    combined_shoot_mask = apply_shoot_roi_mask(combined_shoot_mask, shoot_roi)\n",
    "    combined_shoot_mask = refine_mask_for_shoots(combined_shoot_mask, min_pixels=2)\n",
    "    shoot_bboxes = extract_bounding_boxes_for_shoots(combined_shoot_mask, min_area=2)\n",
    "\n",
    "    # Segment roots using both models\n",
    "    root_mask1 = segment_image_in_patches(root_model1, cropped_img)\n",
    "    root_mask2 = segment_image_in_patches(root_model2, cropped_img)\n",
    "\n",
    "    # Combine root predictions \n",
    "    combined_root_mask = (root_mask1 + root_mask2)\n",
    "\n",
    "    # Refine the combined root mask\n",
    "    combined_root_mask = refine_mask_for_roots(combined_root_mask, min_pixels=1)\n",
    "\n",
    "    # Extract root bounding boxes\n",
    "    root_bboxes = extract_bounding_boxes_for_roots(combined_root_mask, min_area=1)\n",
    "\n",
    "    # Filter bboxes to those below the shoot ROI\n",
    "    filtered_root_bboxes_in_shoot_roi = [\n",
    "        bbox for bbox in root_bboxes\n",
    "        if bbox[1] >= shoot_roi[1] and bbox[1] < (shoot_roi[1] + shoot_roi[3])\n",
    "    ]\n",
    "\n",
    "    # Divide the region into zones (5) inside the shoot ROI\n",
    "    zones_within_roi = calculate_zone_boundaries_within_roi(shoot_roi, num_zones=5, img_width=image_width)\n",
    "    roots_by_zone = assign_roots_to_zones_within_roi(filtered_root_bboxes_in_shoot_roi, zones_within_roi)\n",
    "\n",
    "    # Pick primary root in each zone with bounding box extension\n",
    "    extended_roots_by_zone = select_primary_root_with_extensions(\n",
    "        filtered_root_bboxes_in_shoot_roi, shoot_roi, zones_within_roi, image_width\n",
    "    )\n",
    "\n",
    "    # Extract skeleton masks and measure length per zone\n",
    "    primary_roots_dict = {\n",
    "        zone: root_info['bbox']\n",
    "        for zone, root_info in extended_roots_by_zone.items()\n",
    "        if root_info is not None\n",
    "    }\n",
    "\n",
    "    skeletonized_roots_by_zone, root_lengths_by_zone, root_tips_by_zone = extract_region_masks_with_tips(\n",
    "        primary_roots_dict,\n",
    "        combined_root_mask,\n",
    "        cropped_img\n",
    "    )\n",
    "\n",
    "    # Optional visualizations\n",
    "    if visualize:\n",
    "        visualize_predictions_with_tips(\n",
    "            cropped_img,\n",
    "            shoot_bboxes,\n",
    "            filtered_root_bboxes_in_shoot_roi,\n",
    "            roots_by_zone,\n",
    "            shoot_roi,\n",
    "            root_tips_by_zone,\n",
    "            title=\"Filtered Predictions with Tips\"\n",
    "        )\n",
    "\n",
    "    return {\"Root Lengths by Zone\": root_lengths_by_zone, \"Root Tips by Zone\": root_tips_by_zone}\n",
    "\n",
    "# ======================================\n",
    "#   Batch Execution Across Directory\n",
    "# ======================================\n",
    "def run_analysis_across_directory(root_model1, root_model2, shoot_model1, shoot_model2, folder_path, visualize=False):\n",
    "    \"\"\"\n",
    "    Process all images in the directory and return the analysis results.\n",
    "    Optionally, visualize the results for each image.\n",
    "    \"\"\"\n",
    "    # Validate folder_path is a directory\n",
    "    if not os.path.isdir(folder_path):\n",
    "        raise NotADirectoryError(f\"Provided path '{folder_path}' is not a directory.\")\n",
    "    \n",
    "    gathered_data = []\n",
    "\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        if file_name.lower().endswith(('.png', '.jpg', '.jpeg')):  # Accept common image formats\n",
    "            image_path = os.path.join(folder_path, file_name)\n",
    "            try:\n",
    "                # Load the image\n",
    "                original_image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "                if original_image is None:\n",
    "                    print(f\"Warning: Skipping file {file_name} (unable to load image).\")\n",
    "                    continue\n",
    "                \n",
    "                # Run the main pipeline with dual shoot models\n",
    "                results = main_pipeline_with_dual_shoot_models_and_tips(\n",
    "                    root_model1_path=root_model1,\n",
    "                    root_model2_path=root_model2,\n",
    "                    shoot_model1_path=shoot_model1,\n",
    "                    shoot_model2_path=shoot_model2,\n",
    "                    data_dir=image_path,\n",
    "                    visualize=visualize\n",
    "                )\n",
    "                # Format results\n",
    "                for zone, length in results[\"Root Lengths by Zone\"].items():\n",
    "                    tip = results[\"Root Tips by Zone\"].get(zone, None)\n",
    "                    plant_id = f\"{os.path.splitext(file_name)[0]}_plant_{zone + 1}\"\n",
    "                    gathered_data.append([plant_id, length, tip])\n",
    "            except Exception as err:\n",
    "                print(f\"Failed to process {file_name}: {err}\")\n",
    "\n",
    "    # Return results as a list\n",
    "    return gathered_data\n",
    "\n",
    "\n",
    "# ======================================\n",
    "#  Running the analysis\n",
    "# ======================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    root_model1_path = 'converted_models/converted_AlexiKehayias_232230_unet_model_Iteration_1_Root_Final_256px.h5'\n",
    "    root_model2_path = 'converted_models/converted_AlexiKehayias_232230_unet_model_Iteration_10_Test_256px.h5'\n",
    "    shoot_model1_path = 'converted_models/converted_AlexiKehayias_232230_unet_model_Iteration_1_Shoot_Final_256px.h5'\n",
    "    shoot_model2_path = 'converted_models/converted_AlexiKehayias_232230_unet_model_Iteration_1_Shoot_256px.h5'\n",
    "    data_dir = 'C:/Users/User/Desktop/2024-25b-fai2-adsai-AlexiKehayias232230/datalab_tasks/task8/Test_Data'\n",
    "\n",
    "    results = run_analysis_across_directory(\n",
    "        root_model1=root_model1_path,\n",
    "        root_model2=root_model2_path,\n",
    "        shoot_model1=shoot_model1_path,\n",
    "        shoot_model2=shoot_model2_path,\n",
    "        folder_path=data_dir,\n",
    "        visualize=True\n",
    "    )\n",
    "\n",
    "    for result in results:\n",
    "        print(result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alexi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
